<!DOCTYPE html>





<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.4.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="起源机器学习的各项算法，都可以简单理解为：一个向量vector，经过一个函数f(x)，结果得到另一个向量vector或者标量scalar。输入的这个向量，我们称之为样本sample，向量中的每一个值，代表了样本的每一维特征feature。这个向量一般是浮点数的，即dtype=np.float32。  在NLP的相关领域中，我们的样本往往是一段文本内容，如一个句子、一篇文章等等，我们不能把这些文本">
<meta name="keywords" content="Word2Vec">
<meta property="og:type" content="article">
<meta property="og:title" content="现代NLP的基石 - Word2Vec">
<meta property="og:url" content="https://ethaniz.github.io/2019/09/word2vec/index.html">
<meta property="og:site_name" content="机器学习之道">
<meta property="og:description" content="起源机器学习的各项算法，都可以简单理解为：一个向量vector，经过一个函数f(x)，结果得到另一个向量vector或者标量scalar。输入的这个向量，我们称之为样本sample，向量中的每一个值，代表了样本的每一维特征feature。这个向量一般是浮点数的，即dtype=np.float32。  在NLP的相关领域中，我们的样本往往是一段文本内容，如一个句子、一篇文章等等，我们不能把这些文本">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://i.loli.net/2019/09/10/cXgEFD47ewZpmoJ.png">
<meta property="og:image" content="https://i.loli.net/2019/09/10/qfMGJs7cwhdBnU4.png">
<meta property="og:image" content="https://i.loli.net/2019/09/10/N6Htnv8AJhdp4Og.png">
<meta property="og:image" content="https://i.loli.net/2019/09/10/5ZANefGBoP9npxh.png">
<meta property="og:image" content="https://i.loli.net/2019/09/10/4x51QCPY9eBKwbc.png">
<meta property="og:image" content="https://i.loli.net/2019/09/10/yjgV8NnSTFsY5eO.png">
<meta property="og:image" content="https://i.loli.net/2019/09/10/PmEfvMoHG8NZQJw.png">
<meta property="og:updated_time" content="2019-09-25T07:27:05.333Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="现代NLP的基石 - Word2Vec">
<meta name="twitter:description" content="起源机器学习的各项算法，都可以简单理解为：一个向量vector，经过一个函数f(x)，结果得到另一个向量vector或者标量scalar。输入的这个向量，我们称之为样本sample，向量中的每一个值，代表了样本的每一维特征feature。这个向量一般是浮点数的，即dtype=np.float32。  在NLP的相关领域中，我们的样本往往是一段文本内容，如一个句子、一篇文章等等，我们不能把这些文本">
<meta name="twitter:image" content="https://i.loli.net/2019/09/10/cXgEFD47ewZpmoJ.png">
  <link rel="canonical" href="https://ethaniz.github.io/2019/09/word2vec/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>现代NLP的基石 - Word2Vec | 机器学习之道</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">机器学习之道</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Zen of Machine Learning</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-schedule">
      
    

    <a href="/schedule/" rel="section"><i class="menu-item-icon fa fa-fw fa-calendar"></i> <br>Schedule</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="https://ethaniz.github.io/2019/09/word2vec/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="异尘">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://i.loli.net/2019/09/25/KGXIwNR1j3CxSkd.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="机器学习之道">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">现代NLP的基石 - Word2Vec

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-09-10 15:14:24" itemprop="dateCreated datePublished" datetime="2019-09-10T15:14:24+08:00">2019-09-10</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-09-25 15:27:05" itemprop="dateModified" datetime="2019-09-25T15:27:05+08:00">2019-09-25</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/NLP/" itemprop="url" rel="index"><span itemprop="name">NLP</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><img src="https://i.loli.net/2019/09/10/cXgEFD47ewZpmoJ.png" alt="Zv8mc6ulBIVCneD.png"></p>
<h2 id="起源"><a href="#起源" class="headerlink" title="起源"></a>起源</h2><p>机器学习的各项算法，都可以简单理解为：一个向量vector，经过一个函数f(x)，结果得到另一个向量vector或者标量scalar。输入的这个向量，我们称之为样本sample，向量中的每一个值，代表了样本的每一维特征feature。这个向量一般是浮点数的，即<code>dtype=np.float32</code>。 </p>
<p>在NLP的相关领域中，我们的样本往往是一段文本内容，如一个句子、一篇文章等等，我们不能把这些文本直接喂给机器学习模型，而是要先把文本转换成浮点数的向量，即文本的向量化表示。这在NLP领域中是非常基础且重要的阶段，其结果可以用在文档搜索，网页搜索，垃圾邮件过滤，文本主题建模等等方面。</p>
<hr>
<h2 id="BOW"><a href="#BOW" class="headerlink" title="BOW"></a>BOW</h2><p>在文本的向量话表示领域中，最早出现的方法是BOW（Bag Of Words），即词袋模型。这个模型利用onehot编码的思想，把每一个词看作是一个维度，然后一个文档或句子就可以表示成一个维度为N的向量，N为语料中词语的个数。每个维度具体的值，可以通过简单计数或者计算TF-IDF值来得出。实际方案可参考<code>Scikit Learn</code>的<code>CountVectorizer</code>和<code>TfidfVectorizer</code>。</p>
<div align="center">
    <img width="300" height="300" src="https://i.loli.net/2019/09/10/qfMGJs7cwhdBnU4.png">
</div>

<p>这种方式简单，但是效果一般，因为它忽略了很多信息，比如在一个句子中词语的顺序。另外，由于每个词语都是独立的维度，词与词之间的距离（相关）都是相等的，这也明显不合理。</p>
<hr>
<h2 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h2><p>Word2vec <a href="https://arxiv.org/abs/1301.3781" target="_blank" rel="noopener">1301.3781 Efficient Estimation of Word Representations in Vector Space</a>是这个领域非常重要的理念。我认为，Word2Vec是NLP迈向深度学习的基石，通过embedding的方法，让模型能够理解到每个词背后的隐藏含义。 </p>
<p>Word2Vec认为，每一个词都可以表示为一个密集多维向量（相比BOW中的稀疏向量），且这个向量可以捕捉词与词之间的关联。显然，密集的浮点向量，对于机器学习模型是非常友好的。</p>
<div align="center">
    <img width="300" height="140" src="https://i.loli.net/2019/09/10/N6Htnv8AJhdp4Og.png">
</div>

<p>Word2Vec除了采用密集浮点向量来表示每一个单词外，还能实现一个特殊的功能，把数学运算和文本结合起来，比如著名的“king-man-queen-woman”图如下所示：</p>
<div align="center">
    <img width="300" height="300" src="https://i.loli.net/2019/09/10/5ZANefGBoP9npxh.png">
</div>

<p>采用Word2Vec表示以后，我们可以通过矩阵运算，得出 king-man = queen-woman的等式，即词语的向量中，包含了king和queen中关于王权的概念，同时也包含了man和woman的男女之别。 </p>
<p>Word2Vec按照实现算法，可分为两类：</p>
<h3 id="CBOW"><a href="#CBOW" class="headerlink" title="CBOW"></a>CBOW</h3><p>CBOW(Continuous Bag Of Words)是实现word2vec的算法之一。它在每个词语上构造了一个滑动窗口，即词语的上下文-词周围的那些词。每个词都用一个固定长度的向量来表示，然后就可以根据词周围的词来预测中间那个词。 </p>
<p>在训练过程中，根据每次的预测情况，使用GradientDesent方法，不断调整周围词的向量，当训练完成以后，每个词都会作为中心词，把周围的词向量进行了调整，而这种调整是统一的，即求出的gradient值会同样作用到每个周围词的词向量中。 </p>
<p>值得注意的是，在实际操作过程中，周围词的向量会首先通过sum或者concat的方式组合在一起，然后进行预测，在训练过程中，每个epoch计算的次数跟整个文本的词数几乎相等，复杂度大概为O(V)。</p>
<div align="center">
    <img width="300" height="190" src="https://i.loli.net/2019/09/10/4x51QCPY9eBKwbc.png">
    <img width="400" height="290" src="https://i.loli.net/2019/09/10/yjgV8NnSTFsY5eO.png">
</div>

<p>更通俗一点的理解，相当于1个老师对应了K个学生，K个学生（周围词）都会从老师（中心词）那里学习知识，但是老师（中心词）是一视同仁的，教给大家一样的知识。因此，这种方式对于具体某个学生，学习的结果不一定是最好的，但是整个班级的训练过程是效率最高最快的。</p>
<h3 id="Skip-gram"><a href="#Skip-gram" class="headerlink" title="Skip-gram"></a>Skip-gram</h3><p>Skip-gram是word2vec的另一种实现算法。它跟cbow完全相反，即使用一个词来预测它周围的词。在skip-gram中，会利用对周围词的预测情况，使用GradientDecent来不断的调整中心词的词向量，最终所有文本遍历完以后，也就得到了文本所有词的词向量。 </p>
<p>可以看出，skip-gram的训练次数是要多于cbow的，因为每个词在作为中心词时，都需要把它周围的词全部预测一次，这样相当于比cbow的方法多进行了K-1次（假设K为窗口大小），因此复杂度为O(KV)。</p>
<div align="center">
    <img width="500" height="280" src="https://i.loli.net/2019/09/10/PmEfvMoHG8NZQJw.png">
</div>

<p>如图所示，这里的窗口值为2，蓝色的词是输入，窗口内的其他词为输出，这样将一个句子转化为训练样本。 </p>
<p>在skip-gram当中，每个词都要受到周围词的影响，每个词在作为中心词的时候，都要进行K次的预测、调整，因此，当数据量较少的时候，或者词为生僻词出现次数较少时，这种多次的调整会使得词向量更加的准确。 </p>
<p>对比上面的老师与学生的比喻，在skip-gram中，每个词作为中心词时，其实是1个学生 对应了K个老师，K个老师（周围词）都会对学生（中心词）进行训练，这样单个学生的能力就会相对扎实一些，但是这种训练方式整个班级的学习时间肯定更长。</p>
<h3 id="Negative-Sample"><a href="#Negative-Sample" class="headerlink" title="Negative Sample"></a>Negative Sample</h3><p>按照正常的训练逻辑，cbow和skip-gram都是分类模型，分类类别数等于语料中词语的个数。因此模型在最后的softmax层非常巨大，会导致训练的时间非常长，且需要非常大的训练数据来收敛模型和避免over-fitting。 </p>
<p>举个例子，若有一个包含10000个单词的词汇表，而向量特征为300维，则在最后一层Dense层会有300x10000个权重需要更新。 </p>
<p>为了解决这个问题，word2vec的作者提出了2个方案： </p>
<ul>
<li>Subsampling frequent words：以一定的阈值过滤掉了一些高频词，比如“the”，这样可以在一定程度上减少训练数据的数量。 </li>
<li>Negative sampling：改变优化目标函数，使得每一个训练样本只更新网络的小部分权重。 </li>
</ul>
<p>举个例子，在训练样本(”fox”, “quick”)时，我们的输出（标签）为一个one-hot向量，且代表”quick”的神经元输出为1，代表其他成千上万的词的神经元输出为0。采用了negative sampling后，我们首先随机选取一小部分”negative”词语（比如5个）去更新网络的权重，而”positive”词语依然也会更新网络权重。如果在网络的输出层，以前是300x10000的矩阵，现在只需要更新1+5=6个单词，即300x6个权重，是以前的0.06%。在Tensorflow中，有现成的辅助函数<code>tf.nn.nce_loss()</code>可供使用。而在具体的negative samples的选取上，使用了“unigram distribution”，即更频繁使用的词语更容易被选取。</p>
<hr>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文介绍了Word2Vec的起源及相应实现的2种算法cbow和skip-gram，详细对比了这两种算法的原理、训练方式及优缺点，还介绍了Word2Vec训练时的重要trick: negative sampling。Word2Vec虽然不算深度学习，但是它带来的embedding的概念却是现代NLP乃至深度学习的基石，后续我们会继续介绍由此发展的Doc2Vec、Item2Vec、Anything2Vec。</p>

    </div>

    
    
    
        <div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center;">
  <img id="wechat_subscriber_qcode" src="/uploads/wechat-qcode.jpg" alt="异尘 wechat" style="width: 200px; max-width: 100%;">
  <div>欢迎您扫一扫上面的微信公众号，订阅我的博客</div>
</div>

      
        
      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/Word2Vec/" rel="tag"># Word2Vec</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2019/07/web-topic-extractor/" rel="next" title="任意网页正文内容主题词提取">
                  <i class="fa fa-chevron-left"></i> 任意网页正文内容主题词提取
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2019/09/neo4j-tutorial/" rel="prev" title="手把手教你快速入门知识图谱 - Neo4J教程">
                  手把手教你快速入门知识图谱 - Neo4J教程 <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#起源"><span class="nav-number">1.</span> <span class="nav-text">起源</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BOW"><span class="nav-number">2.</span> <span class="nav-text">BOW</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Word2Vec"><span class="nav-number">3.</span> <span class="nav-text">Word2Vec</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CBOW"><span class="nav-number">3.1.</span> <span class="nav-text">CBOW</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Skip-gram"><span class="nav-number">3.2.</span> <span class="nav-text">Skip-gram</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Negative-Sample"><span class="nav-number">3.3.</span> <span class="nav-text">Negative Sample</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">4.</span> <span class="nav-text">总结</span></a></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="https://i.loli.net/2019/09/25/KGXIwNR1j3CxSkd.jpg"
      alt="异尘">
  <p class="site-author-name" itemprop="name">异尘</p>
  <div class="site-description" itemprop="description"></div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">8</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">categories</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">tags</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://www.zhihu.com/people/yi-chen-25-73" title="知乎 &rarr; https://www.zhihu.com/people/yi-chen-25-73" rel="noopener" target="_blank"><i class="fa fa-fw fa-globe"></i>知乎</a>
      </span>
    
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">异尘</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.4.0</div>

        












        
      </div>
    </footer>
  </div>

  


    
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.0"></script><script src="/js/motion.js?v=7.4.0"></script>
<script src="/js/schemes/pisces.js?v=7.4.0"></script>

<script src="/js/next-boot.js?v=7.4.0"></script>



  





















  

  

  

</body>
</html>
